{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMASUM Model Evaluation\n",
    "\n",
    "This is a small notebook to leverage the Rouge metric to measure how well AMASUM stacks up against state-of-art models like Chat GPT when generating summaries for customer reviews on e-commerce websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "I have copied some of the text from the modelling notebook into here to compare.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Model Summary Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-2 F1 Score: 0.5032258014618106\n",
      "ROUGE-L F1 Score: 0.661157019796462\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Define your extractive summary and reference summary as strings\n",
    "extractive_summary = (\n",
    " '- The rotor is praised for its direct fit, perfect performance, and easy '\n",
    " 'installation, making it a recommended product for Honda Accord owners.\\n'\n",
    " '- The reviewer notes that the rotor is of better quality than the one it '\n",
    " 'replaced, and at a cheaper price compared to local parts stores. '\n",
    " 'Additionally, it solved a start problem during wet weather.\\n'\n",
    " '- There are no specific issues or concerns mentioned in the review, '\n",
    " 'indicating that the rotor is generally well-liked and effective.\\n'\n",
    ")\n",
    "# chat gpt reference summary.\n",
    "reference_summary = ('- This review discusses the effectiveness and quality of the rotor for a '\n",
    " '1999 Honda Accord LX, comparing it favorably to the original product '\n",
    " 'supplied by Honda.\\n'\n",
    " '- The rotor is praised for being a direct fit and for its perfect '\n",
    " 'performance, as well as being easy to install.\\n'\n",
    " '- The reviewer also notes that the rotor is of better quality than the one '\n",
    " 'it replaced, and at a cheaper price compared to local parts stores. '\n",
    " 'Additionally, it solved a start problem during wet weather.')\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(extractive_summary, reference_summary)\n",
    "\n",
    "# Access specific ROUGE metrics (e.g., ROUGE-2, ROUGE-L)\n",
    "rouge_2_f1 = scores[0][\"rouge-2\"][\"f\"]\n",
    "rouge_l_f1 = scores[0][\"rouge-l\"][\"f\"]\n",
    "\n",
    "# Print the scores\n",
    "print(\"ROUGE-2 F1 Score:\", rouge_2_f1)\n",
    "print(\"ROUGE-L F1 Score:\", rouge_l_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This is night and day difference from our baseline summaries which I will remind you here were:\n",
    "- **ROUGE-2 F1 Score**: 0.08053690791585993\n",
    "- **ROUGE-L F1 Score**: 0.2079999950924801\n",
    "\n",
    "Our Positive Model is generating summaries that reach approximately **66%** of the effectiveness demonstrated by ChatGPT 3.5 Turbo. This indicates a substantial proficiency of AMASUM in this task.\n",
    "\n",
    "Lets take a look at the Negative Model results now.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Model Summary Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-2 F1 Score: 0.5064935015145894\n",
      "ROUGE-L F1 Score: 0.6837606787902696\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Define your extractive summary and reference summary as strings\n",
    "extractive_summary = (\n",
    "  '- Brightness and compatibility issues: Many customers found that these '\n",
    " 'license plate lights were not bright enough and did not fit their specific '\n",
    " 'car models, leading to disappointment and the need for returns.\\n'\n",
    " '- Light output: The light output was a major concern for customers, with '\n",
    " 'some mentioning that the lights appeared blue instead of white and were not '\n",
    " 'as bright as expected.\\n'\n",
    " '- Desire for brighter options: Some customers expressed a desire for '\n",
    " 'brighter license plate lights, indicating a preference for more powerful '\n",
    " 'options.\\n'\n",
    ")\n",
    "# chat gpt reference summary.\n",
    "reference_summary = ('- Many customers found that these license plate lights were not bright '\n",
    " 'enough and did not meet their expectations.\\n'\n",
    " '- Compatibility was a major issue, with customers reporting that the lights '\n",
    " 'were not suitable for their specific car models, leading to disappointment '\n",
    " 'and the need for returns.\\n'\n",
    " '- Some customers were particularly dissatisfied with the light output, with '\n",
    " 'one customer mentioning that the lights appeared blue instead of white, and '\n",
    " 'others expressing a desire for brighter options.')\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(extractive_summary, reference_summary)\n",
    "\n",
    "# Access specific ROUGE metrics (e.g., ROUGE-2, ROUGE-L)\n",
    "rouge_2_f1 = scores[0][\"rouge-2\"][\"f\"]\n",
    "rouge_l_f1 = scores[0][\"rouge-l\"][\"f\"]\n",
    "\n",
    "# Print the scores\n",
    "print(\"ROUGE-2 F1 Score:\", rouge_2_f1)\n",
    "print(\"ROUGE-L F1 Score:\", rouge_l_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Lovely!\n",
    "\n",
    "We are getting about **68%** of the effectiveness demonstrated by ChatGPT 3.5 Turbo with the Negative Model. \n",
    "\n",
    "I am more than pleased with the first iteration of this model. Fine-tuned on opensource materials we are closer to getting to state-of-the-art model like Open AI's GPT and with more training on the full dataset and more powerful GPU's I beleive we could get even closer.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstonelast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
